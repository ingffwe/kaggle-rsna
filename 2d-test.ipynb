{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 5)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "# Effnet\n",
    "WEIGHTS = tv.models.efficientnet.EfficientNet_V2_S_Weights.DEFAULT\n",
    "RSNA_2022_PATH = '../input/rsna-2022-cervical-spine-fracture-detection'\n",
    "TRAIN_IMAGES_PATH = f'{RSNA_2022_PATH}/train_images'\n",
    "TEST_IMAGES_PATH = f'{RSNA_2022_PATH}/test_images'\n",
    "EFFNET_MAX_TRAIN_BATCHES = 4000\n",
    "EFFNET_MAX_EVAL_BATCHES = 200\n",
    "ONE_CYCLE_MAX_LR = 0.0001\n",
    "ONE_CYCLE_PCT_START = 0.3\n",
    "SAVE_CHECKPOINT_EVERY_STEP = 1000\n",
    "EFFNET_CHECKPOINTS_PATH = '../input/rsna-2022-base-effnetv2'\n",
    "FRAC_LOSS_WEIGHT = 2.\n",
    "N_FOLDS = 5\n",
    "METADATA_PATH = '../input/vertebrae-detection-checkpoints'\n",
    "\n",
    "PREDICT_MAX_BATCHES = 1e9\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if DEVICE == 'cuda':\n",
    "    BATCH_SIZE = 32\n",
    "else:\n",
    "    BATCH_SIZE = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EffnetModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        effnet = tv.models.efficientnet_v2_s(weights=WEIGHTS)\n",
    "        self.model = create_feature_extractor(effnet, ['flatten'])\n",
    "        self.nn_fracture = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1280, 7),\n",
    "        )\n",
    "        self.nn_vertebrae = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1280, 7),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # returns logits\n",
    "        x = self.model(x)['flatten']\n",
    "        return self.nn_fracture(x), self.nn_vertebrae(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        frac, vert = self.forward(x)\n",
    "        return torch.sigmoid(frac), torch.sigmoid(vert)\n",
    "\n",
    "model = EffnetModel()\n",
    "model.predict(torch.randn(1, 3, 512, 512))\n",
    "del model\n",
    "\n",
    "def weighted_loss(y_pred_logit, y, reduction='mean', verbose=False):\n",
    "    \"\"\"\n",
    "    Weighted loss\n",
    "    We reuse torch.nn.functional.binary_cross_entropy_with_logits here. pos_weight and weights combined give us necessary coefficients described in https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/340392\n",
    "\n",
    "    See also this explanation: https://www.kaggle.com/code/samuelcortinhas/rsna-fracture-detection-in-depth-eda/notebook\n",
    "    \"\"\"\n",
    "\n",
    "    neg_weights = (torch.tensor([7., 1, 1, 1, 1, 1, 1, 1]) if y_pred_logit.shape[-1] == 8 else torch.ones(y_pred_logit.shape[-1])).to(DEVICE)\n",
    "    pos_weights = (torch.tensor([14., 2, 2, 2, 2, 2, 2, 2]) if y_pred_logit.shape[-1] == 8 else torch.ones(y_pred_logit.shape[-1]) * 2.).to(DEVICE)\n",
    "\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        y_pred_logit,\n",
    "        y,\n",
    "        reduction='none',\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print('loss', loss)\n",
    "\n",
    "    pos_weights = y * pos_weights.unsqueeze(0)\n",
    "    neg_weights = (1 - y) * neg_weights.unsqueeze(0)\n",
    "    all_weights = pos_weights + neg_weights\n",
    "\n",
    "    if verbose:\n",
    "        print('all weights', all_weights)\n",
    "\n",
    "    loss *= all_weights\n",
    "    if verbose:\n",
    "        print('weighted loss', loss)\n",
    "\n",
    "    norm = torch.sum(all_weights, dim=1).unsqueeze(1)\n",
    "    if verbose:\n",
    "        print('normalization factors', norm)\n",
    "\n",
    "    loss /= norm\n",
    "    if verbose:\n",
    "        print('normalized loss', loss)\n",
    "\n",
    "    loss = torch.sum(loss, dim=1)\n",
    "    if verbose:\n",
    "        print('summed up over patient_overall-C1-C7 loss', loss)\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def evaluate_effnet(model: EffnetModel, ds, max_batches=PREDICT_MAX_BATCHES, shuffle=False):\n",
    "    torch.manual_seed(42)\n",
    "    model = model.to(DEVICE)\n",
    "    dl_test = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=os.cpu_count(),\n",
    "                                          collate_fn=filter_nones)\n",
    "    pred_frac = []\n",
    "    pred_vert = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        frac_losses = []\n",
    "        vert_losses = []\n",
    "        with tqdm(dl_test, desc='Eval', miniters=10) as progress:\n",
    "            for i, (X, y_frac, y_vert) in enumerate(progress):\n",
    "                with autocast():\n",
    "                    y_frac_pred, y_vert_pred = model.forward(X.to(DEVICE))\n",
    "                    frac_loss = weighted_loss(y_frac_pred, y_frac.to(DEVICE)).item()\n",
    "                    vert_loss = torch.nn.functional.binary_cross_entropy_with_logits(y_vert_pred, y_vert.to(DEVICE)).item()\n",
    "                    pred_frac.append(torch.sigmoid(y_frac_pred))\n",
    "                    pred_vert.append(torch.sigmoid(y_vert_pred))\n",
    "                    frac_losses.append(frac_loss)\n",
    "                    vert_losses.append(vert_loss)\n",
    "\n",
    "                if i >= max_batches:\n",
    "                    break\n",
    "        return np.mean(frac_losses), np.mean(vert_losses), torch.concat(pred_frac).cpu().numpy(), torch.concat(pred_vert).cpu().numpy()\n",
    "\n",
    "# quick test\n",
    "m = EffnetModel()\n",
    "frac_loss, vert_loss, pred1, pred2 = evaluate_effnet(m, ds_train, max_batches=2)\n",
    "frac_loss, vert_loss, pred1.shape, pred2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "effnet_models = []\n",
    "for name in tqdm(range(N_FOLDS)):\n",
    "    effnet_models.append(load_model(EffnetModel(), f'effnetv2-f{name}', EFFNET_CHECKPOINTS_PATH))\n",
    "\n",
    "def gen_effnet_predictions(effnet_models, df_train):\n",
    "\n",
    "    df_train_predictions = []\n",
    "    with tqdm(enumerate(effnet_models), total=len(effnet_models), desc='Folds') as progress:\n",
    "        for fold, effnet_model in progress:\n",
    "            ds_eval = EffnetDataSet(df_train.query('split == @fold'), TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n",
    "\n",
    "            frac_loss, vert_loss, effnet_pred_frac, effnet_pred_vert = evaluate_effnet(effnet_model, ds_eval, PREDICT_MAX_BATCHES)\n",
    "            progress.set_description(f'Fold score:{frac_loss:.02f}')\n",
    "            df_effnet_pred = pd.DataFrame(data=np.concatenate([effnet_pred_frac, effnet_pred_vert], axis=1),\n",
    "                                          columns=[f'C{i}_effnet_frac' for i in range(1, 8)] +\n",
    "                                                  [f'C{i}_effnet_vert' for i in range(1, 8)])\n",
    "\n",
    "            df = pd.concat(\n",
    "                [df_train.query('split == @fold').head(len(df_effnet_pred)).reset_index(drop=True), df_effnet_pred],\n",
    "                axis=1\n",
    "            ).sort_values(['StudyInstanceUID', 'Slice'])\n",
    "            df_train_predictions.append(df)\n",
    "    df_train_predictions = pd.concat(df_train_predictions)\n",
    "    return df_train_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pred = gen_effnet_predictions(effnet_models, df_train)\n",
    "df_pred.to_csv('train_predictions.csv', index=False)\n",
    "df_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_sample_patient(df_pred):\n",
    "    patient = np.random.choice(df_pred.StudyInstanceUID)\n",
    "    df = df_pred.query('StudyInstanceUID == @patient').reset_index()\n",
    "\n",
    "    plt.subplot(1, 3, 1).plot((df[[f'C{i}_fracture' for i in range(1, 8)]].values * df[[f'C{i}' for i in range(1, 8)]].values))\n",
    "    f'Patient {patient}, fractures'\n",
    "\n",
    "    df[[f'C{i}_effnet_frac' for i in range(1, 8)]].plot(\n",
    "        title=f'Patient {patient}, fracture prediction',\n",
    "        ax=(plt.subplot(1, 3, 2)))\n",
    "\n",
    "    df[[f'C{i}_effnet_vert' for i in range(1, 8)]].plot(\n",
    "        title=f'Patient {patient}, vertebrae prediction',\n",
    "        ax=plt.subplot(1, 3, 3)\n",
    "    )\n",
    "\n",
    "plot_sample_patient(df_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_cols = ['patient_overall'] + [f'C{i}_fracture' for i in range(1, 8)]\n",
    "frac_cols = [f'C{i}_effnet_frac' for i in range(1, 8)]\n",
    "vert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]\n",
    "\n",
    "\n",
    "def patient_prediction(df):\n",
    "    c1c7 = np.average(df[frac_cols].values, axis=0, weights=df[vert_cols].values)\n",
    "    pred_patient_overall = 1 - np.prod(1 - c1c7)\n",
    "    return np.concatenate([[pred_patient_overall], c1c7])\n",
    "\n",
    "df_patient_pred = df_pred.groupby('StudyInstanceUID').apply(lambda df: patient_prediction(df)).to_frame('pred').join(df_pred.groupby('StudyInstanceUID')[target_cols].mean())\n",
    "df_patient_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = np.stack(df_patient_pred.pred.values.tolist())\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "targets = df_patient_pred[target_cols].values\n",
    "targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('CV score:', weighted_loss(torch.logit(torch.as_tensor(predictions)).to(DEVICE), torch.as_tensor(targets).to(DEVICE)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}